{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc97735",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "The goal of this document is simply to explore the code within RITSAR and give step by step visualization to the ongoing processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5067809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic Import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pathlib\n",
    "%matplotlib notebook\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we need to find and bring our data files into memory\n",
    "#The data file we will be using is in the data folder, specifically data/AFRL/pass1\n",
    "#We have to start from the 'parent' directory which is '.'\n",
    "directory='./data/AFRL/pass1'\n",
    "\n",
    "#Our AFRL file reading code requires a starting azimuth and polarization\n",
    "#I leave the details of file naming convention to the reader, let's cheat\n",
    "subfile1='HH/data_3dsar_pass1_az001_HH.mat'\n",
    "subfile2='HH/data_3dsar_pass1_az002_HH.mat'\n",
    "subfile3='HH/data_3dsar_pass1_az003_HH.mat'\n",
    "subfile4='HH/data_3dsar_pass1_az004_HH.mat'\n",
    "\n",
    "#\n",
    "name=pathlib.Path(directory + '/' + subfile1)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the .mat files (oddly complicated because they don't read as a dictionary even though they are built that way)\n",
    "\n",
    "#https://stackoverflow.com/questions/7008608/scipy-io-loadmat-nested-structures-i-e-dictionaries\n",
    "#User: mergen Date: 17 Jan 2012 Accessed: April 2019.\n",
    "import scipy.io as sio # in import section already\n",
    "def mergenloadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = sio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dictdata):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dictdata:\n",
    "        if isinstance(dictdata[key], sio.matlab.mio5_params.mat_struct):\n",
    "            dictdata[key] = _todict(dictdata[key])\n",
    "    return dictdata        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dictdata = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, sio.matlab.mio5_params.mat_struct):\n",
    "            dictdata[strg] = _todict(elem)\n",
    "        else:\n",
    "            dictdata[strg] = elem\n",
    "    return dictdata\n",
    "\n",
    "file1data=mergenloadmat(pathlib.Path(directory + '/' + subfile1))['data']\n",
    "file2data=mergenloadmat(pathlib.Path(directory + '/' + subfile2))['data']\n",
    "file3data=mergenloadmat(pathlib.Path(directory + '/' + subfile3))['data']\n",
    "file4data=mergenloadmat(pathlib.Path(directory + '/' + subfile4))['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's explore what the data looks like\n",
    "for key in file1data.keys():\n",
    "    try:\n",
    "        print(key, '  ', file1data[key].shape)\n",
    "    except:\n",
    "        print(key, '  ', 'No shape for this ')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file1data['af'].keys())\n",
    "#these aren't used in our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now it's time to join this data into a phase history\n",
    "#first, let's look at the sub components\n",
    "keys=file1data.keys()\n",
    "key='fp' if 'fp' in keys else 'fq' #Used for compatibility\n",
    "phs_tmp1= file1data[key].T\n",
    "phs_tmp2= file2data[key].T\n",
    "phs_tmp3= file3data[key].T\n",
    "phs_tmp4= file4data[key].T\n",
    "\n",
    "fig,ax=plt.subplots(4,1)\n",
    "\n",
    "ax[0].imshow(np.abs(phs_tmp1),cmap='gray')\n",
    "ax[1].imshow(np.abs(phs_tmp2),cmap='gray')\n",
    "ax[2].imshow(np.abs(phs_tmp3),cmap='gray')\n",
    "ax[3].imshow(np.abs(phs_tmp4),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68151f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join the phase histories ‐--------------, -------‐--------\n",
    "phs=np.vstack([phs_tmp1,phs_tmp2,phs_tmp3,phs_tmp4])\n",
    "plt.figure()               \n",
    "plt.imshow(np.abs(phs),cmap='gray')\n",
    "plt.ylabel('pulse')\n",
    "plt.xlabel('sample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ad772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore the other parameters-----------------------------\n",
    "freq1= np.float64(file1data['freq'])\n",
    "freq2= np.float64(file2data['freq'])\n",
    "freq3= np.float64(file3data['freq'])\n",
    "freq4= np.float64(file4data['freq'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(freq1,label='freq1')\n",
    "plt.plot(freq2,label='freq2')\n",
    "plt.plot(freq3,label='freq3')\n",
    "plt.plot(freq4,label='freq4')\n",
    "plt.legend()\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's look at flight position---------------------------------------‐------------\n",
    "pos1 = np.vstack((file1data['x'], file1data['y'], file1data['z'])).T\n",
    "pos2 = np.vstack((file2data['x'], file2data['y'], file2data['z'])).T\n",
    "pos3 = np.vstack((file3data['x'], file3data['y'], file3data['z'])).T\n",
    "pos4 = np.vstack((file4data['x'], file4data['y'], file4data['z'])).T\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(pos1[:,0],pos1[:,1],label='pos1')\n",
    "ax.plot(pos2[:,0],pos2[:,1],label='pos2')\n",
    "ax.plot(pos3[:,0],pos3[:,1],label='pos3')\n",
    "ax.plot(pos4[:,0],pos4[:,1],label='pos4')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's look at r0, th, and phi\n",
    "#I'm not seeing these getting used in image formation----------------\n",
    "#I see the same variable names, but they don't come from platform\n",
    "\n",
    "#r0\n",
    "fig,ax=plt.subplots(3,1)\n",
    "ax[0].plot(file1data['r0'], label=\"r0 - 1\")\n",
    "ax[0].plot(file2data['r0'], label=\"r0 - 2\")\n",
    "ax[0].plot(file3data['r0'], label=\"r0 - 3\")\n",
    "ax[0].plot(file4data['r0'], label=\"r0 - 4\")\n",
    "ax[0].legend()\n",
    "\n",
    "#th\n",
    "ax[1].plot(file1data['th'], label=\"th - 1\")\n",
    "ax[1].plot(file2data['th'], label=\"th - 2\")\n",
    "ax[1].plot(file3data['th'], label=\"th - 3\")\n",
    "ax[1].plot(file4data['th'], label=\"th - 4\")\n",
    "ax[1].legend()\n",
    "\n",
    "#phi\n",
    "ax[2].plot(file1data['phi'], label=\"phi - 1\")\n",
    "ax[2].plot(file2data['phi'], label=\"phi - 2\")\n",
    "ax[2].plot(file3data['phi'], label=\"phi - 3\")\n",
    "ax[2].plot(file4data['phi'], label=\"phi - 4\")\n",
    "ax[2].legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ba3bab9",
   "metadata": {},
   "source": [
    "# Start the real business\n",
    "Now that we know what the data looks like, let's start calculating the things we'll need to form an image, specifically with polar formating we know the parameters we will need are:\n",
    "    c           =   299792458.0\n",
    "    npulses     =   platform['npulses']\n",
    "    f_0         =   platform['f_0']\n",
    "    pos         =   np.asarray(platform['pos'])\n",
    "    k           =   platform['k_r']\n",
    "    R_c         =   platform['R_c']\n",
    "    n_hat       =   img_plane['n_hat']\n",
    "    k_ui        =   img_plane['k_u']\n",
    "    k_vi        =   img_plane['k_v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e06e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#these first two parameters are easy\n",
    "c=299792458.0\n",
    "npulses = phs.shape[0]\n",
    "nsamples = phs.shape[1]\n",
    "\n",
    "#looks like we need to get the illusive f_0, the center frequency, which wasn't a parameter we got from the data. \n",
    "#The code does a linear regression to get this, but lets see how close we get with the average of max and min\n",
    "freq=freq1\n",
    "f_1=(np.max(freq)+np.min(freq))/2\n",
    "print(f_1)\n",
    "\n",
    "\n",
    "from scipy.stats import linregress\n",
    "B_IF        = freq.max()-freq.min()\n",
    "delta_t     = 1.0/B_IF\n",
    "t           = np.linspace(-nsamples/2, nsamples/2, nsamples)*delta_t\n",
    "\n",
    "chirprate, f_0, r, p, s\\\n",
    "            = linregress(t, freq)\n",
    "print(f_0)\n",
    "\n",
    "print('it appears taking the average is close, but not the same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's take a closer look at what's going on here\n",
    "fig,ax=plt.subplots(2,1)\n",
    "ax[0].plot(t,freq,label='freq')\n",
    "ax[0].axhline(f_1,label='avg',color='r')\n",
    "ax[0].axhline(f_0,label='regress',color='g')\n",
    "\n",
    "x1=-1e-12\n",
    "x2=1e-12\n",
    "y1=np.min([f_1,f_0])-10\n",
    "y2=np.max([f_1,f_0])+10\n",
    "\n",
    "# Make the zoom-in plot:\n",
    "ax[1].plot(t,freq,label='freq')\n",
    "ax[1].axhline(f_1,label='avg',color='r')\n",
    "ax[1].axhline(f_0,label='regress',color='g')\n",
    "\n",
    "ax[1].set_xlim(x1, x2)\n",
    "ax[1].set_ylim(y1, y2)\n",
    "#plt.xticks(visible=False)\n",
    "#plt.yticks(visible=False)\n",
    "#plt.draw()\n",
    "#plt.show()\n",
    "\n",
    "ax[1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting position is easy----------,,,,----------\n",
    "pos=np.vstack([pos1, pos2, pos3, pos4])\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb98c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now it's time for k space items‐-----------------------\n",
    "k_r=4*np.pi*freq/c #units of meters\n",
    "plt.figure()    \n",
    "plt.plot(t,k_r)\n",
    "\n",
    "#R_c is easy, it's just the middle of the aperture\n",
    "#todo:put R_c as a vector on the plot for flight path\n",
    "if np.mod(npulses,2)>0:\n",
    "    R_c = pos[npulses//2]\n",
    "else:\n",
    "    R_c = np.mean(\n",
    "        pos[npulses//2-1:npulses//2+1],\n",
    "        axis = 0)\n",
    "print(R_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3da104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's time for the hardest part of all of this---------------------\n",
    "# figuring out the image plane characteristics\n",
    "\n",
    "# to keep with the example, I'll use res_factor, upsample, and aspect\n",
    "# upsample triggers the strict use of a power of 2 which\n",
    "# is equal or larger to the current number of samples/pulses\n",
    "nu= 2**int(np.log2(nsamples)+bool(np.mod(np.log2(nsamples),1)))\n",
    "nv= 2**int(np.log2(npulses)+bool(np.mod(np.log2(npulses),1)))\n",
    "print(\"number of samples: \", nsamples)\n",
    "print(\"number of pulses: \", npulses)\n",
    "print(\"pixels in u direction\", nu)\n",
    "print(\"pixels in v direction\", nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res factor determines how much of the image will lie in the grid\n",
    "res_factor=1.4 #from the example\n",
    "aspect=1 #from the example\n",
    "\n",
    "# delta_r originally from platform calcs but needed here first\n",
    "# delta_r is the theoretical range resolution limit\n",
    "delta_r = c/(2*B_IF) #speed of light over double the bandwidth\n",
    "du = delta_r*res_factor*nsamples/nu\n",
    "aspect=aspect if aspect else 1.0\n",
    "dv = aspect*du\n",
    "#Define range and cross-range locations\n",
    "u = np.arange(-nu/2, nu/2)*du\n",
    "v = np.arange(-nv/2, nv/2)*dv\n",
    "\n",
    "#Derive image plane spatial frequencies\n",
    "#both of these are in units if Cycles per meter\n",
    "k_u = 2*np.pi*np.linspace(-1.0/(2*du), 1.0/(2*du), nu)\n",
    "k_v = 2*np.pi*np.linspace(-1.0/(2*dv), 1.0/(2*dv), nv)\n",
    "\n",
    "\n",
    "#not needed for polar formatting, great for display though\n",
    "#Represent u and v in (x,y,z)\n",
    "[uu,vv] = np.meshgrid(u,v)\n",
    "#uu = uu.flatten(); vv = vv.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0848ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's visualize some things we've now done\n",
    "fig,ax=plt.subplots(2,1)\n",
    "ax[0].plot(k_u)\n",
    "ax[1].plot(k_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d1732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not used in polar formating, but fun to see\n",
    "# removed to save notebook size\n",
    "#fig,ax=plt.subplots(2,1)\n",
    "#a0=ax[0].imshow(uu)\n",
    "#ax[0].set_title('u coordinate for bp')\n",
    "#fig.colorbar(a0, ax=[ax[0]], location = 'right') \n",
    "#a1=ax[1].imshow(vv)\n",
    "#ax[1].set_title('v coordinate for bp')                \n",
    "#fig.colorbar(a1, ax=[ax[1]], location = 'right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7baeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uu = uu.flatten(); vv = vv.flatten()\n",
    "\n",
    "#fig,ax=plt.subplots(2,1)\n",
    "#ax[0].plot(uu)\n",
    "#ax[1].plot(vv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76563708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #determine the vector directions of u and v---------------------------------\n",
    "n_hat = np.array([0,0,1])\n",
    "print(R_c/np.linalg.norm(R_c))\n",
    "v_hat = np.cross(n_hat, R_c)/np.linalg.norm(np.cross(n_hat, R_c))\n",
    "u_hat = np.cross(v_hat, n_hat)/np.linalg.norm(np.cross(v_hat, n_hat))\n",
    "\n",
    "print(v_hat)#almost y direction\n",
    "print(u_hat)#almost x direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute x and y unit vectors. x defined to lie along R_c.\n",
    "#z = np.cross(vec[0], vec[-1]); z =z/np.linalg.norm(z)\n",
    "print(R_c)\n",
    "u_hat = (R_c-np.dot(R_c,n_hat)*n_hat)/\\\n",
    "        np.linalg.norm((R_c-np.dot(R_c,n_hat)*n_hat))\n",
    "v_hat = np.cross(u_hat,n_hat)\n",
    "\n",
    "print(v_hat)#negative y direction?\n",
    "print(u_hat)#almost x direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda58903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we finish building the image plane dictionary by saving it\n",
    "img_plane =\\\n",
    "    {\n",
    "    'n_hat'     :   n_hat,\n",
    "    'u_hat'     :   u_hat,\n",
    "    'v_hat'     :   v_hat,\n",
    "    'du'        :   du,\n",
    "    'dv'        :   dv,\n",
    "    'u'         :   u,\n",
    "    'v'         :   v,\n",
    "    'k_u'       :   k_u,\n",
    "    'k_v'       :   k_v,\n",
    "#    'pixel_locs':   pixel_locs # 3 x N_pixel array specifying x,y,z location\n",
    "                               # of each pixel\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040bcd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_plane['n_hat'])\n",
    "print(img_plane['u_hat'])\n",
    "print(img_plane['v_hat'])\n",
    "print(img_plane['du'])\n",
    "print(img_plane['dv'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81fa7eae",
   "metadata": {},
   "source": [
    "#Retrieve relevent parameters\n",
    "    c           =   299792458.0\n",
    "    npulses     =   platform['npulses']\n",
    "    f_0         =   platform['f_0']\n",
    "    pos         =   np.asarray(platform['pos'])\n",
    "    k           =   platform['k_r']\n",
    "    R_c         =   platform['R_c']\n",
    "    n_hat       =   img_plane['n_hat']\n",
    "    k_ui        =   img_plane['k_u']\n",
    "    k_vi        =   img_plane['k_v']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1b0e9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Begin polar formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7205a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute k_xi offset\n",
    "psi = np.pi/2-np.arccos(np.dot(R_c,n_hat)/np.linalg.norm(R_c))\n",
    "k_ui = k_u + 4*np.pi*f_0/c*np.cos(psi)\n",
    "#I'm not sure what this is for.\n",
    "print(psi)\n",
    "print(np.cos(psi))\n",
    "print(4*np.pi*f_0/c*np.cos(psi))\n",
    "#so we've shifted our range direction frequency space based on graze/squint at center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916635b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display the new k_ui and the \n",
    "fig,ax = plt.subplots(2,1)\n",
    "ax[0].plot(k_ui) \n",
    "#label this\n",
    "ax[1].plot(k_r)\n",
    "#label this 4*pi*freq/c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df149ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_hat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa908a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute x and y unit vectors. x defined to lie along R_c.\n",
    "#z = np.cross(vec[0], vec[-1]); z =z/np.linalg.norm(z)\n",
    "#u_hat = (R_c-np.dot(R_c,n_hat)*n_hat)/\\\n",
    "#        np.linalg.norm((R_c-np.dot(R_c,n_hat)*n_hat))\n",
    "#v_hat = np.cross(u_hat,n_hat)\n",
    "\n",
    "#v_hat = np.cross(n_hat, R_c)/np.linalg.norm(np.cross(n_hat, R_c))\n",
    "#u_hat = np.cross(v_hat, n_hat)/np.linalg.norm(np.cross(v_hat, n_hat))\n",
    "\n",
    "\n",
    "#Compute r_hat, the diretion of k_r, for each pulse\n",
    "r_norm = np.linalg.norm(pos,axis=1)\n",
    "r_norm = np.array([r_norm]).T\n",
    "r_norm = np.tile(r_norm,(1,3))\n",
    "r_hat = pos/r_norm #unit vector of direction from scene center to platform at each pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to matrices to make projections easier\n",
    "r_hat = np.asmatrix(r_hat)\n",
    "u_hat = np.asmatrix([u_hat])\n",
    "v_hat = np.asmatrix([v_hat])\n",
    "\n",
    "#honestly not sure if this step does anything\n",
    "#matrix multiplication works just fine if you have the shape already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ab0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_r.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_matrix= np.asmatrix(k_r)\n",
    "k_matrix.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd245e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kx and ky meshgrid\n",
    "ku = r_hat*u_hat.T*k_matrix; ku = np.asarray(ku)\n",
    "kv = r_hat*v_hat.T*k_matrix; kv = np.asarray(kv)\n",
    "\n",
    "fig, ax= plt.subplots(2,1)\n",
    "ax[0].imshow(ku)\n",
    "ax[1].imshow(kv)\n",
    "print(ku.max(), ku.min())\n",
    "print(kv.max(), kv.min())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49057012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor(nsamples, S_L=43):\n",
    "    xi = np.linspace(-0.5, 0.5, nsamples)\n",
    "    A = 1.0/np.pi*np.arccosh(10**(S_L*1.0/20))\n",
    "    n_bar = int(2*A**2+0.5)+1\n",
    "    sigma_p = n_bar/np.sqrt(A**2+(n_bar-0.5)**2)\n",
    "    \n",
    "    #Compute F_m\n",
    "    m = np.arange(1,n_bar)\n",
    "    n = np.arange(1,n_bar)\n",
    "    F_m = np.zeros(n_bar-1)\n",
    "    for i in m:\n",
    "        num = 1\n",
    "        den = 1\n",
    "        for j in n:\n",
    "            num = num*\\\n",
    "            (-1)**(i+1)*(1-i**2*1.0/sigma_p**2/(\\\n",
    "                            A**2+(j-0.5)**2))\n",
    "            if i!=j:\n",
    "                den = den*(1-i**2*1.0/j**2)\n",
    "            \n",
    "        F_m[i-1] = num/den\n",
    "    \n",
    "    w = np.ones(nsamples)\n",
    "    for i in m:\n",
    "        w += F_m[i-1]*np.cos(2*np.pi*i*xi)\n",
    "    \n",
    "    w = w/w.max()          \n",
    "    return(w)\n",
    "\n",
    "#Create taylor windows\n",
    "win1 = taylor(int(phs.shape[1]), S_L = 20)\n",
    "win2 = taylor(int(phs.shape[0]), S_L = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show what taylor weighting looks like\n",
    "plt.figure()\n",
    "plt.plot(win1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9acce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prnt=100\n",
    "\n",
    "#Radially interpolate kx and ky data from polar raster\n",
    "#onto evenly spaced kx_i and ky_i grid for each pulse\n",
    "rad_interp = 0j*np.zeros([npulses,nu])\n",
    "ky_new = np.zeros([npulses,nu])\n",
    "for i in range(npulses):\n",
    "    if prnt:\n",
    "        if i%prnt==0:\n",
    "            print('range interpolating for pulse %i'%(i+1))\n",
    "    rad_interp[i,:] = np.interp(k_ui, ku[i,:], phs[i,:]*win1,\n",
    "        left = 0, right = 0)\n",
    "    ky_new[i,:] = np.interp(k_ui, ku[i,:], kv[i,:])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51704e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this really needs an explanation of what interp is doing--------\n",
    "#interpolation is used to resample the signal data at new sample locations\n",
    "plt.figure()\n",
    "pulsenum1,pulsenum2=np.random.randint(npulses,size=2)\n",
    "plt.scatter(np.arange(len(ku[pulsenum1,:])), ku[pulsenum1,:], label='pulse %d sample locations' %pulsenum1) #\n",
    "plt.scatter(np.arange(len(ku[pulsenum2,:])), ku[pulsenum2,:], label='pulse %d sample locations' %pulsenum2) #\n",
    "plt.scatter(np.arange(len(k_ui)), k_ui, label='new sample locations') #\n",
    "plt.legend() \n",
    "plt.title('change in sample locations')\n",
    "\n",
    "#as you can see in the figure, interp is expanding the range of data while sampling at about the same density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce3f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also important to show kv vs ky_new\n",
    "fig, ax= plt.subplots(2,1)\n",
    "ax[0].imshow(kv)\n",
    "ax[1].imshow(ky_new)\n",
    "print(kv.max(), kv.min())\n",
    "print(ky_new.max(), ky_new.min()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolate in along track direction to obtain polar formatted data\n",
    "polar = 0j*np.zeros([nv,nu])\n",
    "isSort = (ky_new[npulses//2, nu//2] < ky_new[npulses//2+1, nu//2])\n",
    "#isSort seems like a flag to ensure u_hat is in the right direction, but we found earlier the codeisn't consistent with left vs right hand cross product\n",
    "#TODO: fix left vs right cross product, figure out if it's a left looking vs right looking problem\n",
    "if isSort:\n",
    "    for i in range(nu):\n",
    "        if prnt:\n",
    "            if i%prnt==0:\n",
    "                print('cross-range interpolating for sample %i'%(i+1))\n",
    "        polar[:,i] = np.interp(k_v, ky_new[:,i], rad_interp[:,i]*win2,\n",
    "            left = 0, right = 0)\n",
    "else:\n",
    "    for i in range(nu):\n",
    "        if prnt:\n",
    "            if i%prnt==0:\n",
    "                print('cross-range interpolating for sample %i'%(i+1))\n",
    "        polar[:,i] = np.interp(k_v, ky_new[::-1,i], \n",
    "            rad_interp[::-1,i]*win2, left = 0, right = 0)  \n",
    "            \n",
    "phs_polar=np.nan_to_num(polar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd20bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the before, during, and after interpolation data\n",
    "fig, ax= plt.subplots(3,1)\n",
    "ax[0].imshow(np.abs(phs),cmap='gray')\n",
    "ax[1].imshow(np.abs(rad_interp),cmap='gray')\n",
    "ax[2].imshow(np.abs(polar),cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f954b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shift1=np.fft.fftshift(phs_polar)\n",
    "gmi=np.fft.fft2(shift1)\n",
    "img=np.fft.ifftshift(gmi)\n",
    "pre_scale=np.abs(img)\n",
    "\n",
    "dB_scale=[-30,0]\n",
    "img = 10*np.log10(np.abs(img)/np.abs(img).max())\n",
    "img[img == -np.inf] = dB_scale[0]\n",
    "\n",
    "plt.imshow(img,cmap=cm.Greys_r, vmin = dB_scale[0], vmax = dB_scale[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d05f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
